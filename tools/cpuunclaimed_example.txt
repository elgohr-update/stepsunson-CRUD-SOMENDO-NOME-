Demonstrations of cpuunclaimed, the Linux eBPF/bcc version.


This tool samples the length of the CPU run queues and determine when there are
idle CPUs, yet queued threads waiting their turn. It reports the amount of idle
(yet unclaimed by waiting threads) CPU as a system-wide percentage. For
example:

# ./cpuunclaimed.py
Sampling run queues... Output every 1 seconds. Hit Ctrl-C to end.
%CPU  83.00%, unclaimed idle 0.12%
%CPU  87.25%, unclaimed idle 0.38%
%CPU  85.00%, unclaimed idle 0.25%
%CPU  85.00%, unclaimed idle 0.25%
%CPU  80.88%, unclaimed idle 0.00%
%CPU  82.25%, unclaimed idle 0.00%
%CPU  83.50%, unclaimed idle 0.12%
%CPU  81.50%, unclaimed idle 0.00%
%CPU  81.38%, unclaimed idle 0.00%
[...]

This shows a system running at over 80% CPU utilization, and with less than
0.5% unclaimed idle CPUs.

Unclaimed idle CPUs can happen for a number of reasons:

- An application has been bound to some, but not all, CPUs, and has runnable
  threads that cannot migrate to other CPUs due to this configuration.
- CPU affinity: an optimization that leaves threads on CPUs where the CPU
  caches are warm, even if this means short periods of waiting while other
  CPUs are idle. The wait period is tunale (see sysctl, kernel.sched*).
- Scheduler bugs.

An unclaimed idle of < 1% is likely to be CPU affinity, and not usually a
cause for concern. By leaving the CPU idle, overall throughput of the system
may be improved. This tool is best for identifying larger issues, > 2%, due
to the coarseness of its 99 Hertz samples.


This is an 8 CPU system, with an 8 CPU-bound threaded application running that
has been bound to one CPU (via taskset):

# ./cpuunclaimed.py 
Sampling run queues... Output every 1 seconds. Hit Ctrl-C to end.
%CPU  12.63%, unclaimed idle 86.36%
%CPU  12.50%, unclaimed idle 87.50%
%CPU  12.63%, unclaimed idle 87.37%
%CPU  12.75%, unclaimed idle 87.25%
%CPU  12.50%, unclaimed idle 87.50%
%CPU  12.63%, unclaimed idle 87.37%
%CPU  12.50%, unclaimed idle 87.50%
%CPU  12.50%, unclaimed idle 87.50%
[...]

It shows that 7 of the 8 CPUs (87.5%) are idle at the same time there are
queued threads waiting to run on CPU. This is an artificial situation caused
by binding threads to the same CPU, to demonstrate how the tool works.


This is an 8 CPU system running a Linux kernel build with "make -j8", and -T
to print timestamps:

# ./cpuunclaimed.py -T
Sampling run queues... Output every 1 seconds. Hit Ctrl-C to end.
22:25:55 %CPU  98.88%, unclaimed idle 0.12%
22:25:56 %CPU  99.75%, unclaimed idle 0.25%
22:25:57 %CPU  99.50%, unclaimed idle 0.50%
22:25:58 %CPU  99.25%, unclaimed idle 0.75%
22:25:59 %CPU  99.75%, unclaimed idle 0.25%
22:26:00 %CPU  99.50%, unclaimed idle 0.50%
22:26:01 %CPU  99.25%, unclaimed idle 0.75%
22:26:02 %CPU  99.25%, unclaimed idle 0.75%
22:26:03 %CPU  99.01%, unclaimed idle 0.87%
22:26:04 %CPU  99.88%, unclaimed idle 0.12%
22:26:05 %CPU  99.38%, unclaimed idle 0.62%

There's now a consistent, yet small, amount of unclaimed idle CPU. This is
expected to be deliberate: CPU affinity, as mentioned earlier.


The -j option will print raw samples: around one hundred lines of output
every second. For the same system with a Linux kernel build of "make -j8":

# ./cpuunclaimed.py -j
TIMESTAMP_ns,CPU0,CPU1,CPU2,CPU3,CPU4,CPU5,CPU6,CPU7
514606928954752,1,1,1,1,1,1,1,1
514606939054312,1,1,1,1,1,1,1,2
514606949156518,1,1,1,1,1,1,1,1
514606959256596,2,2,1,1,1,1,1,1
514606969357989,1,1,1,1,1,2,1,1
514606979459700,1,2,1,1,1,2,1,1
514606989560481,1,1,1,1,1,1,1,1
514606999661396,1,1,1,1,1,1,2,1
514607009795601,1,1,1,1,1,1,1,2
514607019862711,1,1,1,1,1,1,1,1
514607029963734,1,1,1,1,1,1,1,1
514607040062372,1,1,1,1,1,1,1,1
514607050197735,1,1,1,2,1,1,1,1
514607060266464,1,1,1,1,1,1,1,2
514607070368025,1,1,1,1,1,2,1,1
514607080468375,1,1,1,1,1,1,1,2
514607090570292,3,2,1,1,1,1,1,1
514607100670725,1,1,1,1,1,2,1,1
514607110771946,1,2,1,1,1,1,1,1
514607120873489,1,1,1,1,2,1,2,1
514607130973857,2,1,1,1,3,1,1,1
514607141080056,0,1,1,1,1,2,1,3
514607151176312,1,1,1,2,1,1,1,1
514607161277753,1,1,1,1,1,1,2,1
514607171379095,1,1,1,1,1,1,1,1
514607181479262,1,1,1,1,1,1,1,1
514607191580794,3,1,1,1,1,1,1,1
514607201680952,1,1,1,1,1,1,2,1
514607211783683,1,1,1,1,1,1,1,1
514607221883274,1,1,1,1,1,1,0,1
514607231984244,1,1,1,1,1,1,1,1
514607242085698,1,1,1,1,1,1,1,1
514607252216898,1,2,1,1,1,1,1,1
514607262289420,1,1,1,1,1,2,1,1
514607272389922,1,1,1,1,1,1,1,1
514607282489413,1,1,1,1,1,1,1,1
514607292589950,1,3,1,1,1,1,1,1
514607302693367,1,1,1,1,2,1,1,1
514607312793792,1,1,1,1,1,1,1,1
514607322895249,1,1,1,3,1,1,3,1
514607332994278,1,0,1,1,1,2,1,2
514607343095836,1,1,1,1,1,2,1,1
514607353196533,1,1,1,1,2,1,1,1
514607363297749,1,1,1,1,1,1,1,2
514607373399011,1,1,1,1,1,1,1,2
514607383499730,1,1,1,1,1,1,1,2
514607393601510,1,1,1,1,1,1,1,2
514607403704117,2,1,1,1,1,1,1,2
514607413802700,1,1,1,1,2,1,0,1
514607423904559,1,1,1,1,1,1,1,1
[...]

The output is verbose: printing out a timestamp, and then the length of each
CPU's run queue. The second last line, of timestamp 514607413802700, is an
example of what this tool detects: CPU 4 has a run queue length of 4, which
means one thread running and one thread queued, while CPU 6 has a run queue
length of 0: idle. The very next sample shows all CPUs busy.


The -J option prints raw samples with time offsets showing when the samples
were collected on each CPU. It's mostly useful for debugging the tool itself.
For example, during a Linux kernel build:

# ./cpuunclaimed.py -J
TIMESTAMP_ns,CPU0,CPU1,CPU2,CPU3,CPU4,CPU5,CPU6,CPU7,OFFSET_ns_CPU0,OFFSET_ns_CPU1,OFFSET_ns_CPU2,OFFSET_ns_CPU3,OFFSET_ns_CPU4,OFFSET_ns_CPU5,OFFSET_ns_CPU6,OFFSET_ns_CPU7
514722625198188,1,1,1,1,1,1,1,2,0,28321,51655,73396,89654,111172,132803,159792
514722635299034,1,1,1,1,1,2,1,1,0,28809,51999,74183,89552,110011,131995,153519
514722645400274,1,1,1,1,1,1,1,2,0,28024,51333,7365